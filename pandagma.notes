
Jump to:
  SciNet notes
  Set up Pandagma
  Prepare files for Pandagma
  Run Pandagma
  Command line tricks with Pandagma output files
  Checks
  Add new annotation
  Calculate trees
  Debugging
  First run pan-Zea calculation
  First run grass gene families calculation
  First run dataset fixes and mods
  Classes of errors


*****************************************************************************************
SciNet notes
*****************************************************************************************

log in to Ceres
  https://scinet.usda.gov/guides/access/login
  ssh -o TCPKeepAlive=yes -o ServerAliveInterval=20 -o ServerAliveCountMax=30 USER.NAME@ceres.scinet.usda.gov
  or 
  ssh ceres-login with suggested changes to ~/.ssh/config file
  if needed, set up step
    $ brew install step
    then
    $ step ca bootstrap --ca-url https://step-ca.scinet.usda.gov --fingerprint adb703fd18f176937743b20228d52af7a705d63a0471cd67428660be5fd006bf 
    $ step ssh config --set Provisioner=keycloak --set User=user.name
  log in
    $ ssh ceres-login
    login form pops up in browser

Copy to/from Ceres
  scp [files] ethy.cannon@ceres.scinet.usda.gov:[path]

Go to project directory
  /project/maizegdb/ethy

Also remember:  /90daydata/maizegdb  (more space)

Available disk space: $ my_quotas

Grab some cores before working:
  $ scalloc -c [num cores]

Some conda commands
  $ salloc
  OR
  $ salloc -N 1 -n 36 -t 2:00:00 -p short
  $ ml miniconda
  $ conda list -n pandagma
  $ conda install -c bioconda -n pandagma perl-bio-tools-run-alignment-clustalw
  $ source activate pandagma
  $ conda deactivate # or just exit salloc

project directory (MaizeGDB owns a node)
  /project/maizegdb
  
Slurm commands
  $ sbatch [sbatch file]
  $ sq     # to check if job is running
  Output goes to slurm* and stderr*
  $ scancel [job id]
Am I in salloc?
  $ echo $SLURM_JOB_ID   # returns nothing if not in salloc

Forum: https://forum.scinet.usda.gov (use lincpass)



*****************************************************************************************
Set up Pandagma
*****************************************************************************************

Clone pandagma into project directory
  $ git clone https://github.com/legumeinfo/pandagma.git
  $ cd pandagma
  $ mkdir data_orig  # holds original cds, protein, and gff files
  $ mkdir data  # processed files (script to process files no longer part of pandagma)

Modify/create a config file in pandagma/config/
  Holds paramters and names of files for main, extra-constrained (by matching chr), 
  and extra-free. Chromosome associations can be listed here, or in the file 
  data/expected_chr_matches.tsv.
  
  Important: The bed and cds fasta files must be listed in the same order.

Create an sbatch file. Use the conda example.

$ sbatch [sbatch file]


*****************************************************************************************
Prepare files for Pandagma
*****************************************************************************************

Limit CDS files to canonical transcripts
Protein names need to match transcript names (i.e., _T***)

Preprocessing:
  1. Review overlapping gene models 
      See pandagma_scripts/helers/find_overlapping_gene_models.pl
      CREATE TABLE chado.overlapping_gene_model (
         overlapping_gene_model_id BIGSERIAL,
         gene_model TEXT,
         overlapped_gene_models TEXT
      );
      On curation server:
      # \copy chado.overlapping_gene_model (gene_model, overlapped_gene_models) from '/home/mgdbadmin/support_scripts/GeneModels/data/overlaps.txt' with delimiter E'\t'
  2. Review really long gene models
     SELECT * FROM (
       SELECT gene_model, length,
              ARRAY_LENGTH(STRING_TO_ARRAY(overlapped_gene_models, ','), 1) AS count
       FROM chado.overlapping_gene_model
       WHERE gene_model LIKE 'Zm00001%' OR gene_model LIKE 'GRMZM%' 
             OR gene_model LIKE 'A%' OR gene_model LIKE 'E%'
     ) s WHERE count > 1
     ORDER by length DESC;
  

*****************************************************************************************
Run Pandagma
*****************************************************************************************

Often wise to run ingest by itself, only once.


***********************************************
Command line tricks with Pandagma output files
***********************************************
  # count files of a type
  ls data/*cds.fa* | wc

  # loop, taking advantage of cores
  for file in *gz ; do gunzip $file &[CR!]  # & needs to be at the end of the line
  done

  # longest element in GFF
  cat Zm-B73-REFERENCE-GRAMENE-4.0_Zm00001d.2.gff3 | 
  awk '{if(!($1~/#/)&&!($3~/chromosome/)){print ($5-$4), $3, $4, $5, $9}}' |
  sort -r -k1,1n | head

  # longest element in BED
  zcat Zm-B73-REFERENCE-GRAMENE-4.0_Zm00001d.2.gff3.bed |
  awk '{print ($3-$2), $4}' | sort -r -k1,1n > t

vim tips
  copy batch of lines:
  ma
  d'a
  p

  a single line:
  yy
  p

View histograms
cat STRING_OF_NUMBERS | histogram -n -s1 | histplot.pl -divisor 10

To run perl scripts that require BioPerl:
  inside the pandagma dir:
    salloc
    ml miniconda
    conda env create
    export PANDAGMA_ROOT=//project/maizegdb/ethy/grass-fam/pandagma
    export PATH=$PANDAGMA_ROOT/bin:$PATH
    source activate pandagma


*****************************************************************************************
Checks
*****************************************************************************************

Sequence ids for proteins must match ids in CDS files

File order in cds and gff sections MUST match

Even if empty, these must exist in config file:
  annotation_files_extra_constr=(
  )
  cds_files_extra_constr=(
  )
  annotation_files_extra_free=(
  )
  cds_files_extra_free=(
  )


*****************************************************************************************
Add new annotation
*****************************************************************************************

Add to 18_syn_pan_aug_extra.clust.tsv and 18_syn_pan_aug_extra.hsh.tsv

1) Load modules
   $ salloc -N 1 -n 36 -t 2:00:00 -p short
   $ ml miniconda
   $ source activate pandagma
   $ . config/pan_zea.conf
   $ PATH=/project/maizegdb/ethy/pan-zea/pandagma/bin:$PATH
   
2) Rerun run_add_extra with temporary code changes
   - comment out to this line:
     if [[ -v cds_files_extra_constr ]] || [[ -v cds_files_extra_free ]]
   - comment out calls to mmseqs
   - add this code:
    ##### Special for Zea: redo Zm-B73-REFERENCE-GRAMENE-3.0_Zm00001c using clust_cov_extra="0.24"
    clust_cov_extra="0.24"
    file_base=Zm-B73-REFERENCE-GRAMENE-3.0_Zm00001c.1.cds.longest.fa
    echo "Extra: 02_fasta_nuc/$file_base"
    MMTEMP=$(mktemp -d -p 03_mmseqs_tmp)
    SEQTYPE=3
    mmseqs easy-search "02_fasta_nuc/$file_base" 13_pan_aug_fasta_posn.fna 13_extra_out_constr_dir/"${file_base}".x.all_cons.m8 \
                 "$MMTEMP" --search-type "${SEQTYPE}" --cov-mode 5 -c "${clust_cov_extra}" 1>/dev/null
    ##### End special for Zea
  - run just run_add_extra


*****************************************************************************************
Calculate trees
*****************************************************************************************

Trees for pan-genes need to be calculated by hand; the built-in process doesn't work.

output=$(echo "$input" | sed 's/[aeiou]/#/g')

salloc -N 1 -n 36 -t 4:00:00 -p short
ml miniconda
source activate pandagma
. config/pan_zea.conf
#export PATH=/project/maizegdb/ethy/pan-zea/pandagma/bin:$PATH

[path]/run_pan_tree.sh

Script contents:
export OMP_NUM_THREADS=1
export NPROC=$( ( command -v nproc > /dev/null && nproc ) || getconf _NPROCESSORS_ONLN)
export dir_prefix=2
for filepath in "${dir_prefix}3_hmmalign_trim2"/*; do
  file=$(basename "$filepath")
  num=$(echo "$file" | sed 's/pan//g')
  if [[ $num < $start ]]; then
    echo "Skipping $file"
  fi
  echo "  Calculating tree for $file"
  echo "fasttree -quiet $filepath > ${dir_prefix}4_trees/$file"
  fasttree -quiet "$filepath" > "${dir_prefix}4_trees/$file" &
  # allow to execute up to $NPROC concurrent asynchronous processes
  if [[ $(jobs -r -p | wc -l) -ge ${NPROC} ]]; then wait -n; fi
done


*****************************************************************************************
Debugging
*****************************************************************************************

Run steps individually
  Comment out all but one in sbatch file.

Run ks_calc one at a time:
  cat $DAGFILE | calc_ks_from_dag.pl -fasta_db 02_tmp_fasta.db \
      -match_table 03_mmseqs/$base.db  -align_method precalc \
      -report_out 05_kaksout/$base.rptout &
  ---->
      -report_out 05_kaksout/$base.rptout &> test.out  # stdout and stderr to test.out

Prevent removal of intermediate files:
  pandagma-pan.sh -r -c $CONFIG  # Doesn't work???

Work files:
  01_posn_hsh/, 01_combined_posn.hsh - gene model position hashes
  02_all*.fna                        - all CDS fasta, conveniently located
  03_mmseqs                          - mmseq output for each combination of annotations
  04_dag                             - dagchainer output from 03_mmseqs
  05_filtered_pairs.tsv              - dagchainer output filtered for matching chromosomes


*****************************************************************************************
First run pan-Zea calculation
*****************************************************************************************

Data selection:
  main: B73, NAMs, Chinese FIL, Pan-And Zea
  extra: everything else
  
get data
  get_data/get_pan_zea.sh
  
  NOTE: block comment
  : << "END"
  ...
  END

  Deal with B73 v3 by hand
    --> B73v3 (for safe keeping)
    ARSBox https://iastate.app.box.com/folder/165911971789 (private > MAIZE_GENOMES > B73RefGen_v3)
    Use Zea_mays.AGPv3.22.pandagma.better.gff3.gz
  
    To repeat process:
      Remove repeats and organelle features
        $ awk '{if($3!~/repeat_region/&&$1!~/chrPt/&&$1!~/chrMt/){print}}' Zea_mays.AGPv3.22.gff3 > Zea_mays.AGPv3.22.no_repeats.gff3
      Then edit to remove 'gene:', "transcript:', et cetera
      Convert 'transcript' feature type to 'mRNA'
      Add chromosome records from cvit file
      If necessary,
        get list of gene model names:
           $ perl -nle '/ID=(.*?)_{0,1};/;print "$1"' Zea_mays.AGPv3.22.no_repeats.mod.gff3 \
             | perl -nle 'if(!/.*_T\d+/ && !/.*_P\d+/ && !/.*?FGP/ && !/.*?FGT/){print}' > v3_gene_models.txt
        then make an xref file
      Translate:
        $ perl scripts/ReassignIDs.pl v3_xref.txt Zea_mays.AGPv3.22.no_repeats.gff3 \
             v3_xref.txt > Zea_mays.AGPv3.22.pandagma.gff3
             
      Remove organelle gms from cds
        $ scripts/fasta_to_table.awk Zea_mays.AGPv3.22.cdna.all.pandagma.fa | sort > t
        delete up to Zm00001ca000175_T01 GRMZM2G040843_T01
        $ cat t | perl -pe 's/(^.*?)\t/>$1\n/' > t2
        $ mv t2 Zea_mays.AGPv3.22.cdna.all.pandagma.fa
      
      Make canonical cds file
        $ cat Zm-B73-REFERENCE-GRAMENE-3.0_Zm00001c.1.cds.fa | ../bin/fasta_to_table.awk |
          perl -pe 's/_T(\d+) ?/\tT$1\t/' |
          awk -v FS="\t" -v OFS="\t" '$0!~/provisional/ {print $1, length($4), $2, $3, $4}' |
          sort -k1,1 -k2nr,2nr |
          ../bin/top_line.awk | awk -v FS="\t" '{print ">" $1 "_" $3 " " $4; print $5}' |
          cat > Zm-B73-REFERENCE-GRAMENE-3.0_Zm00001c.1.canonical.cds.fa
        $ gzip Zm-B73-REFERENCE-GRAMENE-3.0_Zm00001c.1.canonical.cds.fa
      
      Make bed file
        $ zcat Zm-B73-REFERENCE-GRAMENE-3.0_Zm00001c.1.gff3.gz | ../bin/gff_to_bed6_mRNA.awk |
          perl -pe '$prefix="Zm00001c"; s/^(\D+)/$prefix.$1/; s/transcript://' |
          cat > Zm-B73-REFERENCE-GRAMENE-3.0_Zm00001c.1.gff3.bed
        $ gzip Zm-B73-REFERENCE-GRAMENE-3.0_Zm00001c.1.gff3.bed

    Clean up B73 v4
      Remove organelle gene models
        $ cat Zm-B73-REFERENCE-GRAMENE-4.0_Zm00001d.2.protein.fa | ../bin/fasta_to_table.awk | 
          grep -v "^GRMZM5G" | perl -pe 's/^([^\t]+)\t/>$1\n/' > tmp.Zm00001d.2.protein.fa
        $ mv tmp.Zm00001d.2.protein.fa Zm-B73-REFERENCE-GRAMENE-4.0_Zm00001d.2.protein.fa
        $ zcat Zm-B73-REFERENCE-GRAMENE-4.0_Zm00001d.2.canonical.cds.fa.gz | ../bin/fasta_to_table.awk | 
        $ grep -v "^GRMZM5G" | perl -pe 's/^([^\t]+)\t/>$1\n/' > Zm00001d.2.canonical.cds.fa
        $ rm Zm-B73-REFERENCE-GRAMENE-4.0_Zm00001d.2.canonical.cds.fa.gz
        $ mv Zm00001d.2.canonical.cds.fa Zm-B73-REFERENCE-GRAMENE-4.0_Zm00001d.2.canonical.cds.fa
        $ gzip Zm-B73-REFERENCE-GRAMENE-4.0_Zm00001d.2.canonical.cds.fa
      Count result(?)
        $ grep -c '>' Zm-B73-REFERENCE-GRAMENE-4.0_Zm00001d.2.protein.fa tmp.Zm00001d.2.protein.fa

Modify config/[config_file]
  To guarantee order:
  $ cat config/pan_zea.conf  | awk 'NR>=22 && NR<=47' | sort > lis.cds_main
  $ cat config/pan_zea.conf  | awk 'NR>=51 && NR<=76' | sort > lis.annot_main
  Copy back into config file
  Visual check:$  paste lis.cds.extra lis.annot.extra

Choose step(s) to run in sbatch file

Run it:
  $ exit    # If in salloc
  $ sbatch sbatch_pan_zea.sh
  $ sq     # to check if job is running
  Check stderr file
  $ scancel [job id]

Alignments
  in dagchainer src dir:
  $ Java_XY_plotter/run_XYplot.pl [dag file]   # reallly, REALLY slow; can't load a full file


*****************************************************************************************
First run grass gene families calculation
*****************************************************************************************

File prep:
  - prepare canonical cds and protein files
  - prefix file names with gene model prefix
  - the gene model prefix needs to be separated from the rest of the name with a .
     e.g. zm00001eb.000010
  - all files need to be gzipped
  
Data selection:
  Av-Kellogg1287_8-REFERENCE-PanAnd-1.0	Anatherum virginicum
  Brachypodium_distachyon-3.0  (5 chrs)
  Hordeum_vulgare_Morex-3.0 (7 chrs)
  Oryza_sativa_IRGSP-1.0 (12 chrs)
  Panicum_hallii_591-2.2
  Setaria_italica-2.0 (9 chrs)
    NOTE: italic uses roman numerals to identify chromosomes!
  Sorghum bicolor (10 chrs)
  Zea mays B73
  
These were problematic; try later:
  Asativa_sang.v1.1 (needs to be modified w/ fix_grasses.pl)
  Eragrostis tef (tetraploid: 10X2 chrs; get pub)
  Panicum_hallii_590-3.2
  Saccharum_spontaneum_Sspon (wild relative of sugarcane; octopolid haploid; 8*4 chrs)
  Setaria_viridis-2.0
  Td-FL_9056069_6-DRAFT-PanAnd-1.0	Tripsacum dactyloides (FL, south;)
  Td-KS_B6_1-DRAFT-PanAnd-1.0	Tripsacum dactyloides (KS, north)
  Td-McKain334_5-DRAFT-PanAnd-1.0	Tripsacum dactyloides 
  Triticum_aestivum_IWGSC (wheat)
  Zea mays pan-genes (in place of B73)

Can't get this one:
  Panicum hallii (PHallii_v3.1; drought tolerant C4; 9 chrs; https://doi.org/10.1038/s41467-018-07669-x)
  Panicum hallii HAL2: FIL2 (PhalliiHAL_v2.1; 9 chrs)
     --> no annotation at ensembl plants
     Archived at JGI, waiting for data (12/23)

PanAnd round 2:
  Ac-Pasquet1232-DRAFT-PanAnd-1.0	Andropogon chinensis
  Ag-CAM1351-DRAFT-PanAnd-1.0	Andropogon gerardii
  Ab-Traiperm_572-DRAFT-PanAnd-1.0	Andropogon burmanicus
  Bl-K1279B-DRAFT-PanAnd-1.0	Bothriochloa laguroides
  Cc-PI314907-DRAFT-PanAnd-1.0	Cymbopogon citratus
  Cr-AUB069-DRAFT-PanAnd-1.0	Cymbopogon refractus
  Cs-KelloggPI219580-DRAFT-PanAnd-1.0	Chrysopogon serrulatus
  Et-Layton_Zhong168-DRAFT-PanAnd-1.0	Elionorus tripsacoides
  Hc-AUB53_1-DRAFT-PanAnd-1.0	Heteropogon contortus
  Hp-KelloggPI404118-DRAFT-PanAnd-1.0	Hemarthria compressa
  Ir-Pasquet1136-DRAFT-PanAnd-1.0	Ischaemum rugosum
  Pi-Clark-DRAFT-PanAnd-1.0	Pogonatherum paniceum
  Pp-Kellogg1297-DRAFT-PanAnd-1.0	Poa pratensis ssp. angustifolia
  Rr-Malcomber3106-DRAFT-PanAnd-1.0	Rhytachne rottboelloides
  Rt-Layton_Zhong169-DRAFT-PanAnd-1.0	Rottboellia tuberculosa (also known as Coelorachis tuberculosa and Mnesithea tuberculosa)
  Sm-PI203595-DRAFT-PanAnd-1.0	Schizachyrium microstachyum
  Sn-CAM1369-DRAFT-PanAnd-1.0	Sorghastrum nutans
  Ss-CAM1384-DRAFT-PanAnd-1.0	Schizachyrium scoparium
  Te-Pasquet1246-DRAFT-PanAnd-1.0	Thelopogon elegans
  Tt-AUB21_1-DRAFT-PanAnd-1.0	Themeda triandra
  Tz-DC_05_58_3A-DRAFT-PanAnd-1.0	Tripsacum zopolitense
  Ud-Pasquet1171-DRAFT-PanAnd-1.0	Urelytrum digitatum
  Vc-Pasquet1098-DRAFT-PanAnd-1.0	Vossia cuspidata


Data cleaning:
  fix_grasses.pl


Check histograms in work_pandagma/stats/ before running steps past ks_calc


Transcript unrelated to gene model:
for file in *gff3; do echo $file; cat $file | grep -v "#" | head -100 | ./rename_gff_IDs.pl; echo; done

cat Br*gff3 | grep -v "#" | head | perl -pe 's/=\w+:/=/g' | ./rename_gff_IDs.pl

cat Br*gff3 | grep -v "#" | awk '$3~/gene|mRNA/' | head
cat Br*gff3 | grep -v "#" | awk '$3~/gene|mRNA/' | head | perl -pe 's/=\w+:/=/g' | ./add_IDs_to_gff_features.pl

# This one!
cat Br*gff3 | grep -v "#" | awk '$3~/mRNA/ {print $9}' | perl -pe 's/=\w+:/=/g' | 
  perl -pe 's/ID=(\w+);Parent=(\w+);.+/$1\t$2/' |
  awk -v OFS="\t" '$2==prev {print $1, $2 "." ct; prev=$2; ct++} 
                   $2!=prev {ct=1; print $1, $2 "." ct; prev=$2}'

Check distributions:
cat 12_syn_pan_aug_pre.clust.tsv | awk '{print NF-1}' | ../bin/histogram.pl -z -n -s1 | ../bin/histplot.pl -d 50 | head -50
cat stats.txt | ../bin/pan_histplot.pl -d 50 -m 25



*****************************************************************************************
First run dataset fixes and mods
*****************************************************************************************

Remove low-confidence gene models (example: Oat)
  # get_HC_genes.pl in pandagma_scripts repository
  $ perl get_HC_genes.pl Asativa_sang.v1.1.gff3 > Asativa_sang.v1.1.HC.gff   
  >> then the transcript names
  $ cat Asativa_sang.v1.1.HC.gff | perl -nle 'if(/ID=(.*?\.\d+);/){print $1}' > Asativa_sang.v1.1.HC.transcripts
  >> new CDS file: (run this in pandagma folder, after activating pandagma)
  $ bin/get_fasta_subset.pl -input_fas=../../grasses/oat/Asativa_sang.v1.1.cds.fa \
     -output_fas=../../grasses/oat/Asativa_sang.v1.1.cds.HC.fa \
     -list_IDs=../../grasses/oat/Asativa_sang.v1.1.HC.transcripts
  >> new protein file:
  $ bin/get_fasta_subset.pl -input_fas=../../grasses/oat/Asativa_sang.v1.1.protein.fa \
     -output_fas=../../grasses/oat/Asativa_sang.v1.1.protein.HC.fa \
     -list_IDs=../../grasses/oat/Asativa_sang.v1.1.HC.transcripts


Make canonical CDS and protein files (example: Oat)
  $ file='Asativa_sang.v1.1.cds.HC.fa'
    base='Asativa_sang.v1.1'
    echo "Write" $file "to" $base".canonical.cds.HC.fa"
    cat $file | ../../grass-fam/pandagma/bin/fasta_to_table.awk |
      awk '{id=gensub(/(.*?)[.][0-9]+$/,"\\1","g",$1);print id,length($2),$1,$2}' |
      sort -k1,1 -k2,2nr |
      awk '{id=gensub(/(.*?)[.][0-9]+$/,"\\1","g",$1);
            if(id==prev&&count<MAX){print $3,$4;count++};
            if(id!=prev){print $3,$4;count=1;prev=id}}' | 
      ../../grass-fam/pandagma/bin/top_line.awk | 
      awk '{print ">" $1; print $2}' |
      cat > $base.canonical.cds.HC.fa


Make bed file from GF F(example: Oat)
  $ file='Asativa_sang.v1.1.HC.gff'
    base='Asativa_sang.v1.1.HC'
    echo "Convert "$file" to "$base".bed"
    cat $file | ../../grass-fam/pandagma/bin/gff_to_bed7_mRNA.awk | 
      cat > $base.bed



*****************************************************************************************
Post-processing
*****************************************************************************************

$ scalloc
$ ml miniconda                                                                 m                                                                                                                                                                                                                                                                                                                                                                                 

First time:
$ conda create --name post-process
$ conda activate post-process
$ ml sqlite3
$ conda install bioconda::perl-dbd-sqlite

Subsequently:
$ ml sqlite3
$ conda activate post-process




*****************************************************************************************
Classes of errors (8/29/24)
*****************************************************************************************

- There are some questionable groupings of gene models via method 1. How reliable was 
  the synteny analysis used when determining that two gene models are the same? Even 
  the connections across annotation version that were done by hand can be incorrect. 
  People do make mistakes, and when making decisions based on the outcome of a synteny 
  study, mistakes can be compounded.

- I've found one case of a gene model hand-assigned to a locus that appears to be from a 
  pre-v3 annoation as it doesn't appear anywhere in the database or browsers (e.g.
   GRMZM2G476954 for aaap26 is from v2). Fortunately, there appear to be only 15 or so 
   such cases, though the ease with which I found one suggests there are many more that
    my db query didn't find.

- There are many cases where a merged or split gene model made it impossible for pandagma 
  to build a reasonable pan-gene. I've found instances of this in all three annotation 
  versions. Some of these also lead to questionable hand-curated groupings, though often 
  documented (e.g. "gene models X and Y are split"), but not in a way that can be used 
  in a bulk analysis. In cases where two adjacent, split gene models were linked to a 
  locus, there is no way that pandagma will do so as well.

- Most of the literature-supported locus-gene model associations appear to be in v3, but 
  the v3 annotation and especially the assembly have significant problems. Given the 
  messiness of the BAC-by-BAC assembly, I'm unsure of the accuracy of aligning the gene 
  models to v5. The new synteny tracks produced by Crossmap and Liftoff point out the 
  challenge, as they often don't agree with each other.

- Some loci are connected to v3 gene models identified as transposons. These are 
  presented differently in the GFF records and are being missed by the pan-gene analysis. 
  Fixing this is non-trivial. 

- Some regions are simply poorly annotated. Synteny analysis may put gene models in the 
  same place on v5, but they may not show much similarity in sequence or structure.

- There are cases of the seemingly wrong transcript selected as the canonical transcript, 
  one that doesn't match either of the other two annotations nor the Helixer prediction 
  (which I know, combines the transcripts).









